{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget, os, gzip, pickle, random, re, sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMDB_URL = 'http://dlvu.github.io/data/imdb.{}.pkl.gz'\n",
    "IMDB_FILE = 'imdb.{}.pkl.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD, START, END, UNK = '.pad', '.start', '.end', '.unk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imdb(final=False, val=5000, seed=0, voc=None, char=False):\n",
    "\n",
    "    cst = 'char' if char else 'word'\n",
    "\n",
    "    imdb_url = IMDB_URL.format(cst)\n",
    "    imdb_file = IMDB_FILE.format(cst)\n",
    "\n",
    "    if not os.path.exists(imdb_file):\n",
    "        wget.download(imdb_url)\n",
    "\n",
    "    with gzip.open(imdb_file) as file:\n",
    "        sequences, labels, i2w, w2i = pickle.load(file)\n",
    "\n",
    "    if voc is not None and voc < len(i2w):\n",
    "        nw_sequences = {}\n",
    "\n",
    "        i2w = i2w[:voc]\n",
    "        w2i = {w: i for i, w in enumerate(i2w)}\n",
    "\n",
    "        mx, unk = voc, w2i['.unk']\n",
    "        for key, seqs in sequences.items():\n",
    "            nw_sequences[key] = []\n",
    "            for seq in seqs:\n",
    "                seq = [s if s < mx else unk for s in seq]\n",
    "                nw_sequences[key].append(seq)\n",
    "\n",
    "        sequences = nw_sequences\n",
    "\n",
    "    if final:\n",
    "        return (sequences['train'], labels['train']), (sequences['test'], labels['test']), (i2w, w2i), 2\n",
    "\n",
    "    # Make a validation split\n",
    "    random.seed(seed)\n",
    "\n",
    "    x_train, y_train = [], []\n",
    "    x_val, y_val = [], []\n",
    "\n",
    "    val_ind = set( random.sample(range(len(sequences['train'])), k=val) )\n",
    "    for i, (s, l) in enumerate(zip(sequences['train'], labels['train'])):\n",
    "        if i in val_ind:\n",
    "            x_val.append(s)\n",
    "            y_val.append(l)\n",
    "        else:\n",
    "            x_train.append(s)\n",
    "            y_train.append(l)\n",
    "\n",
    "    return (x_train, y_train), \\\n",
    "           (x_val, y_val), \\\n",
    "           (i2w, w2i), 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_val, y_val), (i2w, w2i), numcls = load_imdb(final = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_data(data):\n",
    "    max_len = max([len(sent) for sent in data])\n",
    "    for sent in data:\n",
    "        temp = [w2i['.pad']] * (max_len - len(sent))\n",
    "        sent.extend(temp)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_x_train = fixed_data(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(data, batch_size):\n",
    "    batches = []\n",
    "    i = 0\n",
    "    while i < len(data):\n",
    "        temp = data[i:i+200]\n",
    "        batches.append(temp)\n",
    "        i += 200\n",
    "    \n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = create_batches(fixed_x_train, 200)\n",
    "labels = create_batches(y_train,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "batches = list(itertools.zip_longest(batches,fillvalue=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = torch.tensor(batches,dtype = torch.long)\n",
    "labels = torch.tensor(labels, dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Elman(nn.Module):\n",
    "    def __init__(self, insize = 300, outsize = 300, hsize = 300):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(600, 300)\n",
    "        self.lin2 = nn.Linear(300,300)\n",
    "    def forward(self, x, hidden = None):\n",
    "        b, t, e = x.size()\n",
    "        if hidden == None:\n",
    "            hidden = torch.zeros(b, e, dtype = torch.float)\n",
    "        \n",
    "        outs = []\n",
    "        for i in range(t):\n",
    "            inp = torch.cat([x[:, i, :], hidden], dim = 1)\n",
    "            out = F.relu(self.lin1(inp))\n",
    "            out = self.lin2(out)\n",
    "            outs.append(out[:, None,:])\n",
    "        \n",
    "        return torch.cat(outs, dim = 1), hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.emb = nn.Embedding(99430,300)\n",
    "        self.elman = Elman(300,300,300)\n",
    "        self.fc2 = nn.Linear(300,2)\n",
    "    def forward(self,x):\n",
    "        x = self.emb(x)\n",
    "        x = torch.max(F.relu(self.elman(x)[0]),1)[0]\n",
    "        x = self.fc2(x)\n",
    "    \n",
    "        return x\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr = 0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1):\n",
    "    running_loss = 0\n",
    "    for i in range(100):\n",
    "        inputs = batches[i][0]\n",
    "        label = labels[i]  \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs) \n",
    "        loss = F.cross_entropy(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 19:    \n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 20))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('finish training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_x_val = fixed_data(x_val)\n",
    "val_batches = create_batches(fixed_x_val, 200)\n",
    "val_labels = create_batches(y_val,200)\n",
    "val_batches = list(itertools.zip_longest(val_batches,fillvalue=0))\n",
    "val_batches = torch.tensor(val_batches,dtype = torch.long)\n",
    "val_labels = torch.tensor(val_labels,dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i in range(125):\n",
    "        val_inputs = val_batches[i][0]\n",
    "        val_label = val_labels[i]\n",
    "        val_outputs = net(val_inputs)\n",
    "        _, predicted = torch.max(val_outputs.data, 1)\n",
    "        total += val_label.size(0)\n",
    "        correct += (predicted == val_label).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 5000 validation data: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
